{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-World Use Case: Movie Review Sentiment Analysis:\n",
    "\n",
    "    We'll simulate a scenario where our model predicts the sentiment of movie reviews. This approach is commonly used in the movie industry for analyzing audience feedback. Our final model will be able to infer whether a given movie review is positive or negative, helping movie studios gauge the reception of their films in real-time.\n",
    "\n",
    "    1.Understanding Neural Networks through Movie Reviews\n",
    "        We will develop a neural network to analyze movie reviews and predict if the sentiment is positive or negative. This model can be used by film studios or streaming platforms to automate sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Step 2: Implementing Sentiment Analysis Using PyTorch\n",
    "    1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'It': 0, 'I': 1, 'this': 2, 'Absolutely': 3, 'was': 4, 'watching.': 5, 'movie!': 6, 'loved': 7, 'worth': 8, 'Not': 9, 'terrible.': 10, 'fantastic!': 11}\n",
      "Encoded Reviews: [[1, 7, 2, 6], [0, 4, 10], [3, 11], [9, 8, 5]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.modules.transformer\")\n",
    "\n",
    "\n",
    "# Sample movie review data (simplified example)\n",
    "reviews = [\"I loved this movie!\", \"It was terrible.\", \"Absolutely fantastic!\", \"Not worth watching.\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Create vocabulary and encode reviews into numerical format\n",
    "vocab = {word: i for i, word in enumerate(set(\" \".join(reviews).split()))}\n",
    "encoded_reviews = [[vocab[word] for word in review.split()] for review in reviews]\n",
    "\n",
    "# Display encoded reviews\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Encoded Reviews:\", encoded_reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple PyTorch model\n",
    "class SentimentNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(SentimentNN, self).__init__()\n",
    "        self.fc = nn.Linear(vocab_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# Initialize the model\n",
    "vocab_size = len(vocab)\n",
    "model = SentimentNN(vocab_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.7798\n",
      "Epoch 2, Loss: 2.6474\n",
      "Epoch 3, Loss: 2.5329\n",
      "Epoch 4, Loss: 2.4243\n",
      "Epoch 5, Loss: 2.3206\n",
      "Epoch 6, Loss: 2.2215\n",
      "Epoch 7, Loss: 2.1270\n",
      "Epoch 8, Loss: 2.0370\n",
      "Epoch 9, Loss: 1.9515\n",
      "Epoch 10, Loss: 1.8702\n"
     ]
    }
   ],
   "source": [
    "# Dummy training loop\n",
    "for epoch in range(10):  # 10 epochs\n",
    "    epoch_loss = 0\n",
    "    for i, review in enumerate(encoded_reviews):\n",
    "        # Convert to tensor and one-hot encode the input\n",
    "        input_data = torch.zeros(vocab_size, dtype=torch.float32)\n",
    "        for idx in review:\n",
    "            input_data[idx] = 1.0\n",
    "\n",
    "        label = torch.tensor([labels[i]], dtype=torch.float32)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Predicting Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This movie was amazing and thrilling!\n",
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    # Convert review into numerical format\n",
    "    review_words = review.split()\n",
    "    encoded_review = [vocab.get(word, 0) for word in review_words]  # Default to 0 if word is not in vocab\n",
    "    input_data = torch.zeros(vocab_size, dtype=torch.float32)\n",
    "    for idx in encoded_review:\n",
    "        input_data[idx] = 1.0\n",
    "\n",
    "    # Make prediction\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_data)\n",
    "        sentiment = \"Positive\" if prediction.item() >= 0.5 else \"Negative\"\n",
    "        return sentiment\n",
    "\n",
    "# Test the prediction\n",
    "new_review = \"This movie was amazing and thrilling!\"\n",
    "print(f\"Review: {new_review}\")\n",
    "print(f\"Predicted Sentiment: {predict_sentiment(new_review)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Building a Simplified Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharanya/Training/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.7653\n",
      "Epoch 2, Loss: 4.4742\n",
      "Epoch 3, Loss: 4.2300\n",
      "Epoch 4, Loss: 4.0775\n",
      "Epoch 5, Loss: 3.7406\n",
      "Transformer model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Parameters for the Transformer model\n",
    "vocab_size = 100\n",
    "embed_size = 64\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "\n",
    "# Define the Transformer model\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, num_layers):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_size, nhead=num_heads, num_encoder_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "        return self.fc(self.transformer(src, tgt))\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleTransformer(vocab_size, embed_size, num_heads, num_layers)\n",
    "\n",
    "# Example training data (encoded as numbers)\n",
    "src = torch.randint(0, vocab_size, (10, 32))  # 10 sequences of length 32\n",
    "tgt = torch.randint(0, vocab_size, (10, 32))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt)\n",
    "    loss = criterion(output.view(-1, vocab_size), tgt.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Transformer model training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
